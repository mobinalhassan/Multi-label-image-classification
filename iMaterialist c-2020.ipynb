{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "# tf.compat.v1.get_default_graph\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import backend\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from pathlib import Path\n",
    "from IPython import get_ipython\n",
    "import cv2 # CV2 for image manipulation\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local Notebook\n",
    "label_description_path=r'/root/kaggle/label_descriptions.json'\n",
    "sample_submission_path=r'/root/kaggle/sample_submission.csv'\n",
    "train_path='/root/kaggle/train.csv'\n",
    "DATA_DIR = Path('/root/kaggle/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.96 s, sys: 1.1 s, total: 10.1 s\n",
      "Wall time: 10.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "image_df = pd.read_csv(train_path)[:50000]\n",
    "image_df.drop(['EncodedPixels', 'Height', 'Width'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_creater(parm):\n",
    "    return f'{DATA_DIR}/train/{parm[\"ImageId\"]}.jpg'\n",
    "\n",
    "def geather_attribute_1hot(pram):\n",
    "    c_a=[]\n",
    "    c_a.append(pram['ClassId'])\n",
    "    if str(pram['AttributesIds']).split(',')[0] != 'nan':\n",
    "#         print(str(pram['AttributesIds']).split(',')) [int(x)+46 for x in str(pram['AttributesIds']).split(',')]\n",
    "        c_a.extend([int(x)+46 for x in str(pram['AttributesIds']).split(',')])\n",
    "    \n",
    "#     creating_one_hot\n",
    "    targets = np.array(list(c_a), dtype = np.int32)\n",
    "    nb_classes = 46+341+46\n",
    "    res = np.eye(nb_classes)[np.array(targets).reshape(-1)]\n",
    "    return np.asarray(res.reshape(list(targets.shape)+[nb_classes]).sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>ClassId</th>\n",
       "      <th>AttributesIds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>2645d84a17aaad6df76fde13d68e2458</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>2645d84a17aaad6df76fde13d68e2458</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>2645d84a17aaad6df76fde13d68e2458</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>2645d84a17aaad6df76fde13d68e2458</td>\n",
       "      <td>5</td>\n",
       "      <td>136,138,145,148,289,311,317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>2645d84a17aaad6df76fde13d68e2458</td>\n",
       "      <td>0</td>\n",
       "      <td>115,136,142,147,225,295,316,326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                ImageId  ClassId  \\\n",
       "49995  2645d84a17aaad6df76fde13d68e2458       17   \n",
       "49996  2645d84a17aaad6df76fde13d68e2458       24   \n",
       "49997  2645d84a17aaad6df76fde13d68e2458       23   \n",
       "49998  2645d84a17aaad6df76fde13d68e2458        5   \n",
       "49999  2645d84a17aaad6df76fde13d68e2458        0   \n",
       "\n",
       "                         AttributesIds  \n",
       "49995                              NaN  \n",
       "49996                              NaN  \n",
       "49997                              NaN  \n",
       "49998      136,138,145,148,289,311,317  \n",
       "49999  115,136,142,147,225,295,316,326  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# image_df.columns\n",
    "image_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.75 s, sys: 62.7 ms, total: 8.81 s\n",
      "Wall time: 8.81 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "image_df['ImageIdPath']=image_df.apply(path_creater, axis=1)\n",
    "image_df['OneHot_class_attr']=image_df.apply(geather_attribute_1hot, axis=1)\n",
    "image_df.drop([ 'ClassId','AttributesIds'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 400 #224\n",
    "CHANNELS = 3 \n",
    "def parse_function(filename, label):\n",
    "    \"\"\"Function that returns a tuple of normalized image array and labels array.\n",
    "    Args:\n",
    "        filename: string representing path to image\n",
    "        label: 0/1 one-dimensional array of size N_LABELS\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read an image from a file\n",
    "    image_string = tf.io.read_file(filename)\n",
    "    # Decode it into a dense vector\n",
    "    image_decoded = tf.image.decode_jpeg(image_string, channels=CHANNELS)\n",
    "    # Resize it to fixed shape\n",
    "    image_resized = tf.image.resize(image_decoded, [IMG_SIZE, IMG_SIZE])\n",
    "    # Normalize it from [0, 255] to [0.0, 1.0]\n",
    "    image_normalized = image_resized / 255.0\n",
    "    return image_normalized, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10 \n",
    "# AUTOTUNE = tf.data.experimental.AUTOTUNE # Adapt preprocessing and prefetching dynamically to reduce GPU and CPU idle time\n",
    "SHUFFLE_BUFFER_SIZE = 500\n",
    "def create_dataset(filenames, labels, is_training=True):\n",
    "    \"\"\"Load and parse dataset.\n",
    "    Args:\n",
    "        filenames: list of image paths\n",
    "        labels: numpy array of shape (BATCH_SIZE, N_LABELS)\n",
    "        is_training: boolean to indicate training mode\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a first dataset of file paths and labels\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "    # Parse and preprocess observations in parallel\n",
    "#     dataset = dataset.map(parse_function, num_parallel_calls=AUTOTUNE)\n",
    "    dataset = dataset.map(parse_function, num_parallel_calls=2)\n",
    "    \n",
    "    \n",
    "    if is_training == True:\n",
    "        # This is a small dataset, only load it once, and keep it in memory.\n",
    "        dataset = dataset.cache()\n",
    "        # Shuffle the data each buffer size\n",
    "        dataset = dataset.shuffle(buffer_size=SHUFFLE_BUFFER_SIZE)\n",
    "        \n",
    "    # Batch the data for multiple steps\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    # Fetch batches in the background while the model is training.\n",
    "#     dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    dataset = dataset.prefetch(buffer_size=1)\n",
    "    \n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning and Validation dataset shapes!\n",
      "(49900, 3)\n",
      "(100, 3)\n"
     ]
    }
   ],
   "source": [
    "# Shaflling data \n",
    "sufful_img_df=image_df.reindex(np.random.permutation(image_df.index))\n",
    "# sufful_img_df\n",
    "\n",
    "#Spliting data Train and validation\n",
    "def split_vals(a,n): return a[:n], a[n:]\n",
    "n_valid = 300 #int(len(sufful_img_df)/100*1)\n",
    "n_trn = len(sufful_img_df)-n_valid\n",
    "image_df, valid_df = split_vals(sufful_img_df, n_trn)\n",
    "print('Traning and Validation dataset shapes!')\n",
    "print(image_df.shape)\n",
    "print(valid_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=image_df['ImageIdPath'].tolist()\n",
    "y=np.array(image_df['OneHot_class_attr'].values.tolist())\n",
    "\n",
    "X_train, X_test, y_train_bin, y_test = train_test_split(X, y, random_state=42, test_size=0.1)\n",
    "\n",
    "train_ds = create_dataset(X_train, y_train_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Shaflling data \n",
    "# sufful_img_df=image_df.reindex(np.random.permutation(image_df.index))\n",
    "# # sufful_img_df\n",
    "\n",
    "# #Spliting data Train and validation\n",
    "# def split_vals(a,n): return a[:n], a[n:]\n",
    "# n_valid = int(len(sufful_img_df)/100*10)\n",
    "# n_trn = len(sufful_img_df)-n_valid\n",
    "# image_df, valid_df = split_vals(sufful_img_df, n_trn)\n",
    "# print('Traning and Validation dataset shapes!')\n",
    "# print(image_df.shape)\n",
    "# print(valid_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepration of train dataset\n",
    "# X_train=image_df['ImageIdPath'].tolist()\n",
    "# y_train_bin=np.array(image_df['OneHot_class_attr'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _resize_image(image_path):\n",
    "#     IMAGE_SIZE=256\n",
    "#     img = cv2.imread(image_path)\n",
    "#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#     img = cv2.resize(img, (IMAGE_SIZE, IMAGE_SIZE), interpolation=cv2.INTER_AREA)  \n",
    "#     return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_id='ffffbf7014a9e408bfbb81a75bc70638'\n",
    "# img_path=f'{DATA_DIR}/train/{img_id}.jpg'\n",
    "# _resize_image(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size=(5, 5), activation=\"relu\", input_shape=(400,400,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(filters=32, kernel_size=(5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(filters=64, kernel_size=(5, 5), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(filters=64, kernel_size=(5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(433, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 396, 396, 16)      1216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 198, 198, 16)      0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 198, 198, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 194, 194, 32)      12832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 97, 97, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 97, 97, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 93, 93, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 46, 46, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 46, 46, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 42, 42, 64)        102464    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 21, 21, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 21, 21, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 28224)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               3612800   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 433)               28145     \n",
      "=================================================================\n",
      "Total params: 3,816,977\n",
      "Trainable params: 3,816,977\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid=valid_df['ImageIdPath'].tolist()\n",
    "y_valid_bin=np.array(valid_df['OneHot_class_attr'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1256/4491 [=======>......................] - ETA: 10:45 - loss: 0.0499 - accuracy: 0.0480"
     ]
    }
   ],
   "source": [
    "# model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), batch_size=64)\n",
    "model.fit(train_ds, epochs=10, validation_data=create_dataset(X_valid, y_valid_bin), batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss,accuracy=model.evaluate(create_dataset(X_test, y_test),verbose=2)\n",
    "print(f'Loss of our Model: {loss} and Model Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## History of model traning and ploting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying traning and validation loss\n",
    "model_history_dict=model.history.history\n",
    "train_loss=model_history_dict['loss']\n",
    "val_loss=model_history_dict['val_loss']\n",
    "epochs=range(1,len(train_loss) +1)\n",
    "plt.plot(epochs,train_loss,'b',color='r',label='Training Loss')\n",
    "plt.plot(epochs,val_loss,'b',color='g',label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying traning and validation Accuracy\n",
    "train_acc=model_history_dict['acc']\n",
    "val_acc=model_history_dict['val_acc']\n",
    "epochs=range(1,len(train_acc) +1)\n",
    "plt.plot(epochs,train_acc,'b',color='r',label='Training Accuracy')\n",
    "plt.plot(epochs,val_acc,'b',color='g',label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_id='ffffbf7014a9e408bfbb81a75bc70638'\n",
    "img_path=fr'{DATA_DIR}/train/{img_id}.jpg'\n",
    "img = image.load_img(img_path,target_size=(400,400,3))\n",
    "img = image.img_to_array(img)\n",
    "img = img/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes = np.array(train.columns[2:])\n",
    "proba = model.predict(img.reshape(1,400,400,3))\n",
    "print(proba)\n",
    "top_3 = np.argsort(proba[0])[:-4:-1]\n",
    "print(top_3)\n",
    "# for i in range(3):\n",
    "#     print(\"{}\".format(classes[top_3[i]])+\" ({:.3})\".format(proba[0][top_3[i]]))\n",
    "# plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Snapthat (TF1)",
   "language": "python",
   "name": "tf1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
